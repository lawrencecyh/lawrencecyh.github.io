---
layout: post
title:  Fake News
tags: Thoughts English
---

In light of recent political events, a few public figures have openly remarked that Internet companies like Google and Facebook have the responsibility to do more to combat fake or biased news. While I largely believe this is a systematic issue that must be addressed at a more fundamental level, it is nonetheless interesting to talk about a few approaches that might actually make a difference. Here are my conclusions on what may or may not work.

<!--endexcerpt-->

### Audience Education

Fake news is not a problem unless people believe them.

Could tech companies perhaps better educate their users to be mindful and fact-check news articles themselves? In principle, this would certainly alleviate the underlying problem to a large extent, but in my mind it is not a realistic approach.

If we assume the mainstream media reports mostly on facts, the odds of an average, uninformed person reading news articles containing mostly truthful information is relatively high. However, the existence of climate-change denialists or anti-vaccination activists strongly suggests that some people are not merely uninformed -- they are prejudiced and tend to only believe in articles that support their existing views.

It is futile for tech companies to try and educate such people to verify the news they read. These are people who already consciously reject the mainstream media, and giving them easier access to facts will not change anything. Education like this needs to happen at a more personal level, in places like families and schools.

### Balanced Personal Feeds

We often hear the notion that the Internet is a huge echo chamber where most of its citizens live in self-made information bubbles. The Electome Project at MIT's Media Lab made a few intriguing [data visualizations][electome] that are supportive of this claim. This is not at all surprising, as social media sites by nature optimize for user engagement, which often means surfacing content that people already agree with.

What if social networking sites modified their content recommendation systems to provide users with a wider spectrum of viewpoints?

I consider the effectiveness of this approach mediocre at best. According to a Pew Research Center [report][pew], only 8% of voters named Facebook as their primary news source. This number, although significant, pales in comparison to more traditional outlets like CNN or Fox News. If you also account for the these news organizations' large presences on social media platforms, it follows that making one's Facebook feed politically neutral would only marginally influence readers' underlying source of information.

Furthermore, there is very little incentive for tech companies to switch to such a system to begin with. Companies need engaged users to make money, and any software that purposely generates unwanted content is not going to survive very long. An ideal solution must be sustainable from a financial perspective.

### Active Content Curating

After the 2016 US presidential election, Facebook CEO Mark Zuckerberg wrote a [public post][zuckerberg] about his stance on this issue. While I think he significantly underestimates the effect his company has on the election, he does bring up a point that I very strongly agree with:

> While some hoaxes can be completely debunked, a greater amount of content, including from mainstream sources, often gets the basic idea right but some details wrong or omitted.

Conversely, there are accurate stories that are impossible to verify, such as ones with informants whose identities have to be protected. This immediately brings up some tough questions. What counts as fake news? How much of it has to be incorrect before it gets flagged? Are the curators, human or otherwise, well-calibrated and unbiased? There are many gray areas, and it is very easy to go down a slippery slope when handling these issues.

Therefore, I believe advocates of active curating do not understand the full complexity of the problem. I am skeptical of criminalizing defamation for the same reason -- you can generally label violent content or mature language with good accuracy, but fake news is a whole different story.

**Tech companies should not be in the business of defining truth**, and to be honest, they couldn't even they tried.

### Demonetizing Fake News

This brings me to the last approach I will discuss today -- the idea that reduction of advertisement revenue, also known as demonetization, is the best way to combat controversial content.

To give some context, a popular web page plastered with ads can generate some quick revenue with very minimal effort, as described in this [article][nytimes]. The problem is, in the age of digital media where the average user has a very short attention span, it takes novelty to capture a reader's attention. To generate novelty (and clicks), some publishers turn to misleading titles ("clickbaits"), or even fabricated content that by definition do not appear anywhere else.

As a corollary of the previous section, I do not believe in content removal by platform providers. Fortunately, demonetization removes a lot of incentive to publish controversial content and may create the same net effect anyways. Google has already implemented some of this in YouTube for a few years, which results in certain videos generating less or no revenue. Recently, as a response to many big companies pulling ads due to their brands appearing next to offensive content, Google [announced][google] a series of additional initiatives meant to provide advertisers with more manual control over their ad campaign. This specifically includes the ability to blacklist domains and channels.

While this does translate into immediate revenue losses for tech companies, recent events show that there may still be solid financial incentives in the long run. As long as most brands continue to value brand safety, the market will demand less extremist content, and platform providers will quickly move to match that demand. This applies to fake news as well -- publishers will have little monetary gain for generating such controversial content, but .

Demonetization is perhaps the best we can currently do to combat fake news, and there is optimism it might actually make a difference. After all, it removes a very strong incentive without compromising freedom of information or expression -- two core values that define the Internet for our generation.


[electome]: https://news.vice.com/story/journalists-and-trump-voters-live-in-separate-online-bubbles-mit-analysis-shows
[zuckerberg]: https://www.facebook.com/zuck/posts/10103253901916271
[pew]: http://www.journalism.org/2017/01/18/trump-clinton-voters-divided-in-their-main-source-for-election-news/
[google]: https://blog.google/topics/ads/expanded-safeguards-for-advertisers/
[nytimes]: https://www.nytimes.com/2017/01/18/us/fake-news-hillary-clinton-cameron-harris.html
